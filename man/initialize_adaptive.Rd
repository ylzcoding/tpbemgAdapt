% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/auto_find_start.R
\name{initialize_adaptive}
\alias{initialize_adaptive}
\title{Performs the Data-Adaptive Initialization Strategy via Candidate Model Competition.}
\usage{
initialize_adaptive(
  X,
  y,
  omega_init_guess,
  sigmaSq_init_guess,
  iter_pre_opt = 200,
  pre_opt_burnin = 1000,
  pre_opt_samples = 1000,
  iter_burnin_selection = 0,
  iter_selection = 1000,
  candidates = list(horseshoe = list(a = 0.5, b = 0.5), sb = list(a = 0.5, b = 0.1),
    student_t = list(a = 10, b = 1), normal_gamma = list(a = 1, b = 10)),
  woodbury = TRUE,
  IS_period = 1,
  delta1 = 1e-06,
  delta2 = 0.001,
  delta3 = 0.001,
  window_size = 5,
  converge_rule = "hyper",
  approx = FALSE,
  option = "augmented",
  diagX = FALSE
)
}
\arguments{
\item{X, }{y Model matrix and response vector.}

\item{omega_init_guess, }{sigmaSq_init_guess Initial guesses for omega and sigmaSq, typically derived from a fast Ridge fit.}

\item{iter_pre_opt}{Iterations for the pre-optimization EM stage for each candidate.}

\item{pre_opt_burnin, }{pre_opt_samples burn-in and sample size for the Gibbs sampler within each pre-optimization EM step.}

\item{iter_burnin_selection}{Number of burn-in iterations for the main model selection MCMC chain.}

\item{iter_selection}{Number of post-burn-in samples for model selection.}

\item{candidates}{A list defining the candidate models and their fixed (a, b) values.}

\item{...}{Other arguments to be passed to run_em_engine and getsamples.emp.}
}
\value{
A list containing the winning parameters and the name of the winning model.
}
\description{
This function automates the selection of starting points for the main EM_GibbsTPB
algorithm by running a competition between several candidate models (special cases
of the TPB prior). It selects the candidate that best fits the data and returns
its parameters as the starting points.
}
